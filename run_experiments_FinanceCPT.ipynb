{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment on FinanceCPT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.24.4', '2.0.3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "print([np.__version__, pd.__version__])\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "\n",
    "from src.data_preprocessing import preprocess_data\n",
    "from src.plotting import plot_heatmap\n",
    "from src.causal_matrix_evaluation import evaluate_causal_matrices\n",
    "from src.run_causal_discovery import run_varlingam, run_pcmci, run_varlingam_bootstrap\n",
    "from src.rcv_varlingam import run_rcv_varlingam\n",
    "from src.rcv_pcmci import run_rcv_pcmci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ground truth of adjacency matrices from relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/real/FinanceCPT/relationships/random-rels_20_1A.csv\n",
      "Max lag: 1\n",
      "B_matrices shape: (25, 25)\n",
      "Saved adjacency matrices for file A to data/real/FinanceCPT/ground_truth/random-rels_20_1A_adj.csv\n",
      "\n",
      "Processing data/real/FinanceCPT/relationships/random-rels_20_1B.csv\n",
      "Max lag: 1\n",
      "B_matrices shape: (25, 25)\n",
      "Saved adjacency matrices for file B to data/real/FinanceCPT/ground_truth/random-rels_20_1B_adj.csv\n",
      "\n",
      "Processing data/real/FinanceCPT/relationships/random-rels_20_1C.csv\n",
      "Max lag: 1\n",
      "B_matrices shape: (25, 25)\n",
      "Saved adjacency matrices for file C to data/real/FinanceCPT/ground_truth/random-rels_20_1C_adj.csv\n",
      "\n",
      "Processing data/real/FinanceCPT/relationships/random-rels_20_1D.csv\n",
      "Max lag: 1\n",
      "B_matrices shape: (25, 25)\n",
      "Saved adjacency matrices for file D to data/real/FinanceCPT/ground_truth/random-rels_20_1D_adj.csv\n",
      "\n",
      "Processing data/real/FinanceCPT/relationships/random-rels_20_1E.csv\n",
      "Max lag: 1\n",
      "B_matrices shape: (25, 25)\n",
      "Saved adjacency matrices for file E to data/real/FinanceCPT/ground_truth/random-rels_20_1E_adj.csv\n",
      "\n",
      "All files processed successfully.\n"
     ]
    }
   ],
   "source": [
    "def create_adjacency_matrices(input_file, num_nodes):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file, names=['cause', 'effect', 'lag'])\n",
    "    \n",
    "    # Automatically detect the maximum lag\n",
    "    max_lag = df['lag'].max()\n",
    "    \n",
    "    # Initialize adjacency matrices\n",
    "    B_matrices = [np.zeros((num_nodes, num_nodes)) for _ in range(max_lag + 1)]\n",
    "    \n",
    "    # Populate the adjacency matrices\n",
    "    for _, row in df.iterrows():\n",
    "        cause, effect, lag = row['cause'], row['effect'], row['lag']\n",
    "        B_matrices[lag][effect, cause] = 1  # Adjust for 0-based indexing\n",
    "    \n",
    "    print(f\"Processing {input_file}\")\n",
    "    print(f\"Max lag: {max_lag}\")\n",
    "    print(f\"B_matrices shape: {B_matrices[0].shape}\")\n",
    "    \n",
    "    return B_matrices, max_lag\n",
    "\n",
    "def save_ground_truth(B_matrices, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for i, B in enumerate(B_matrices):\n",
    "            np.savetxt(f, B, delimiter=',', fmt='%.3f')\n",
    "            if i < len(B_matrices) - 1:\n",
    "                f.write('\\n')\n",
    "\n",
    "# Base paths\n",
    "input_base_path = 'data/real/FinanceCPT/relationships/'\n",
    "output_base_path = 'data/real/FinanceCPT/ground_truth/'\n",
    "\n",
    "# Process files A through E\n",
    "for letter in 'ABCDE':\n",
    "    input_file = f'{input_base_path}random-rels_20_1{letter}.csv'\n",
    "    output_file = f'{output_base_path}random-rels_20_1{letter}_adj.csv'\n",
    "    \n",
    "    B_matrices, _ = create_adjacency_matrices(input_file, 25)\n",
    "    save_ground_truth(B_matrices, output_file)\n",
    "    \n",
    "    print(f\"Saved adjacency matrices for file {letter} to {output_file}\\n\")\n",
    "\n",
    "print(\"All files processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_to_matrices(csv_path):\n",
    "    # Read the CSV file\n",
    "    with open(csv_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Split the content by double newlines to separate matrices\n",
    "    matrix_strings = content.strip().split('\\n\\n')\n",
    "    \n",
    "    # Convert each matrix string to a numpy array\n",
    "    matrices = []\n",
    "    for matrix_string in matrix_strings:\n",
    "        matrix = np.array([list(map(float, row.split(','))) for row in matrix_string.split('\\n')])\n",
    "        matrices.append(matrix)\n",
    "    \n",
    "    return matrices\n",
    "\n",
    "# Function to load ground truth\n",
    "def load_ground_truth(letter):\n",
    "    ground_truth_path = f'data/real/FinanceCPT/ground_truth/random-rels_20_1{letter}_adj.csv'\n",
    "    try:\n",
    "        return ground_truth_to_matrices(ground_truth_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Ground truth file not found: {ground_truth_path}\")\n",
    "        return None\n",
    "\n",
    "def save_adjacency_matrices_to_results(B_matrices, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for i, B in enumerate(B_matrices):\n",
    "            np.savetxt(f, B, delimiter=',', fmt='%.3f')\n",
    "            if i < len(B_matrices) - 1:\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_experiments():\n",
    "    methods = ['varlingam', 'pcmci', 'rcv_varlingam', 'rcv_pcmci'] #, 'varlingam_bootstrap']\n",
    "    data_types = ['A', 'B', 'C', 'D', 'E']\n",
    "    results = {method: [] for method in methods}\n",
    "\n",
    "    for data_type in data_types:\n",
    "        print(f\"Running experiments for random-rels_20_1{data_type} data...\")\n",
    "        \n",
    "        # Load ground truth for this data type\n",
    "        ground_truth_matrices = load_ground_truth(data_type)\n",
    "        if ground_truth_matrices is None:\n",
    "            print(f\"Skipping data type {data_type} due to missing ground truth\")\n",
    "            continue\n",
    "        \n",
    "        for method in methods:\n",
    "            # Load data\n",
    "            data = pd.read_csv(f'data/real/FinanceCPT/returns/random-rels_20_1{data_type}_returns30007000.csv')\n",
    "            columns = data.columns.tolist()\n",
    "            if \"Date\" in columns:\n",
    "                data = data.drop(['Date'], axis=1).values\n",
    "                columns.remove('Date')\n",
    "            elif \"timestamp\" in columns:\n",
    "                data = data.drop(['timestamp'], axis=1).values\n",
    "                columns.remove('timestamp')\n",
    "            else:\n",
    "                data = data.values\n",
    "\n",
    "            # Preprocess data\n",
    "            data = preprocess_data(data, columns)\n",
    "\n",
    "            # Run causal discovery method\n",
    "            start_time = time.time()\n",
    "\n",
    "            if method == 'varlingam':\n",
    "                result = run_varlingam(data)\n",
    "                adjacency_matrices = result.adjacency_matrices_\n",
    "            elif method == 'pcmci':\n",
    "                adjacency_matrices = run_pcmci(data, columns)\n",
    "            elif method == 'rcv_varlingam':\n",
    "                adjacency_matrices = run_rcv_varlingam(data)\n",
    "            elif method == 'rcv_pcmci':\n",
    "                adjacency_matrices = run_rcv_pcmci(data)\n",
    "            elif method == 'varlingam_bootstrap':\n",
    "                adjacency_matrices = run_varlingam_bootstrap(data)\n",
    "\n",
    "            end_time = time.time()\n",
    "            runtime = round(end_time - start_time, 4)\n",
    "\n",
    "            if len(adjacency_matrices) > len(ground_truth_matrices):\n",
    "                adjacency_matrices_save = adjacency_matrices[:len(ground_truth_matrices)]\n",
    "            else:\n",
    "                adjacency_matrices_save = adjacency_matrices\n",
    "\n",
    "            # Save adjacency matrices\n",
    "            output_file = f'results/real/FinanceCPT/random-rels_20_1{data_type}/adj_matrices_{method}.csv'\n",
    "            save_adjacency_matrices_to_results(adjacency_matrices_save, output_file)\n",
    "\n",
    "            # Evaluate results\n",
    "            evaluation = evaluate_causal_matrices(ground_truth_matrices, adjacency_matrices)\n",
    "\n",
    "            # Store results\n",
    "            result = {\n",
    "                'data_type': data_type,\n",
    "                'SHD': evaluation['shd'],\n",
    "                'F1': evaluation['f1'],\n",
    "                'F1_directed': evaluation['f1_directed'],\n",
    "                'Frobenius': evaluation['fro'],\n",
    "                'runtime': runtime\n",
    "            }\n",
    "            results[method].append(result)\n",
    "\n",
    "    # Calculate average results and save all results for each method\n",
    "    for method in methods:\n",
    "        df_results = pd.DataFrame(results[method])\n",
    "        \n",
    "        # Calculate average and standard deviation for numeric columns only\n",
    "        numeric_columns = df_results.select_dtypes(include=[np.number]).columns\n",
    "        avg_result = df_results[numeric_columns].mean()\n",
    "        std_result = df_results[numeric_columns].std()\n",
    "\n",
    "        # Prepare the average row\n",
    "        avg_row = {}\n",
    "        for column in df_results.columns:\n",
    "            if column == 'data_type':\n",
    "                avg_row[column] = 'average'\n",
    "            elif column == 'runtime':\n",
    "                avg_row[column] = f\"{avg_result[column]:.4f}\"\n",
    "            else:\n",
    "                avg_row[column] = f\"{avg_result[column]:.4f} ± {std_result[column]:.4f}\"\n",
    "\n",
    "        # Add average to results\n",
    "        avg_df = pd.DataFrame([avg_row])\n",
    "        df_results = pd.concat([df_results, avg_df], ignore_index=True)\n",
    "        \n",
    "        # Save results to CSV\n",
    "        df_results.to_csv(f'results/real/FinanceCPT/performance_{method}.csv', index=False)\n",
    "\n",
    "# Run all experiments\n",
    "run_all_experiments()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
