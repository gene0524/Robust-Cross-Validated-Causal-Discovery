{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment on FinanceCPT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "print([np.__version__, pd.__version__])\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "\n",
    "from src.data_preprocessing import preprocess_data\n",
    "from src.plotting import plot_heatmap\n",
    "from src.causal_matrix_evaluation import evaluate_causal_matrices\n",
    "from src.run_causal_discovery import run_varlingam, run_pcmci, run_varlingam_bootstrap\n",
    "from src.robust_varlingam import run_rcv_varlingam\n",
    "from src.robust_pcmci import run_rcv_pcmci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ground truth of adjacency matrices from relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjacency_matrices(input_file, num_nodes):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file, names=['cause', 'effect', 'lag'])\n",
    "    \n",
    "    # Automatically detect the maximum lag\n",
    "    max_lag = df['lag'].max()\n",
    "    \n",
    "    # Initialize adjacency matrices\n",
    "    B_matrices = [np.zeros((num_nodes, num_nodes)) for _ in range(max_lag + 1)]\n",
    "    \n",
    "    # Populate the adjacency matrices\n",
    "    for _, row in df.iterrows():\n",
    "        cause, effect, lag = row['cause'], row['effect'], row['lag']\n",
    "        B_matrices[lag][effect, cause] = 1  # Adjust for 0-based indexing\n",
    "    \n",
    "    print(f\"Processing {input_file}\")\n",
    "    print(f\"Max lag: {max_lag}\")\n",
    "    print(f\"B_matrices shape: {B_matrices[0].shape}\")\n",
    "    \n",
    "    return B_matrices, max_lag\n",
    "\n",
    "def save_ground_truth(B_matrices, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for i, B in enumerate(B_matrices):\n",
    "            np.savetxt(f, B, delimiter=',', fmt='%.3f')\n",
    "            if i < len(B_matrices) - 1:\n",
    "                f.write('\\n')\n",
    "\n",
    "# Base paths\n",
    "input_base_path = 'data/real/FinanceCPT/relationships/'\n",
    "output_base_path = 'data/real/FinanceCPT/ground_truth/'\n",
    "\n",
    "# Process files A through E\n",
    "for letter in 'ABCDE':\n",
    "    input_file = f'{input_base_path}random-rels_20_1{letter}.csv'\n",
    "    output_file = f'{output_base_path}random-rels_20_1{letter}_adj.csv'\n",
    "    \n",
    "    B_matrices, _ = create_adjacency_matrices(input_file, 25)\n",
    "    save_ground_truth(B_matrices, output_file)\n",
    "    \n",
    "    print(f\"Saved adjacency matrices for file {letter} to {output_file}\\n\")\n",
    "\n",
    "print(\"All files processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_to_matrices(csv_path):\n",
    "    # Read the CSV file\n",
    "    with open(csv_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Split the content by double newlines to separate matrices\n",
    "    matrix_strings = content.strip().split('\\n\\n')\n",
    "    \n",
    "    # Convert each matrix string to a numpy array\n",
    "    matrices = []\n",
    "    for matrix_string in matrix_strings:\n",
    "        matrix = np.array([list(map(float, row.split(','))) for row in matrix_string.split('\\n')])\n",
    "        matrices.append(matrix)\n",
    "    \n",
    "    return matrices\n",
    "\n",
    "# Function to load ground truth\n",
    "def load_ground_truth(letter):\n",
    "    ground_truth_path = f'data/real/FinanceCPT/ground_truth/random-rels_20_1{letter}_adj.csv'\n",
    "    try:\n",
    "        return ground_truth_to_matrices(ground_truth_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Ground truth file not found: {ground_truth_path}\")\n",
    "        return None\n",
    "\n",
    "def save_adjacency_matrices_to_results(B_matrices, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for i, B in enumerate(B_matrices):\n",
    "            np.savetxt(f, B, delimiter=',', fmt='%.3f')\n",
    "            if i < len(B_matrices) - 1:\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data_type):\n",
    "    methods = ['varlingam', 'pcmci', 'rcv_varlingam', 'rcv_pcmci']#, 'varlingam_bootstrap']\n",
    "    \n",
    "    # Load ground truth for this data type\n",
    "    ground_truth_matrices = load_ground_truth(data_type)\n",
    "    if ground_truth_matrices is None:\n",
    "        print(f\"Skipping experiments due to missing ground truth\")\n",
    "        return\n",
    "    \n",
    "    for method in methods:\n",
    "        results = []\n",
    "        \n",
    "        # Load data\n",
    "        data = pd.read_csv(f'data/real/FinanceCPT/returns/random-rels_20_1A_returns30007000.csv')\n",
    "        columns = data.columns.tolist()\n",
    "        if \"Date\" in columns:\n",
    "            data = data.drop(['Date'], axis=1).values\n",
    "            columns.remove('Date')\n",
    "        elif \"timestamp\" in columns:\n",
    "            data = data.drop(['timestamp'], axis=1).values\n",
    "            columns.remove('timestamp')\n",
    "        else:\n",
    "            data = data.values\n",
    "        \n",
    "        # Preprocess data\n",
    "        data = preprocess_data(data, columns)\n",
    "        \n",
    "        # Run causal discovery method\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if method == 'varlingam':\n",
    "            result = run_varlingam(data)\n",
    "            adjacency_matrices = result.adjacency_matrices_\n",
    "        elif method == 'pcmci':\n",
    "            adjacency_matrices = run_pcmci(data, columns)\n",
    "        elif method == 'rcv_varlingam':\n",
    "            adjacency_matrices = run_rcv_varlingam(data)\n",
    "        elif method == 'rcv_pcmci':\n",
    "            adjacency_matrices = run_rcv_pcmci(data)\n",
    "        elif method == 'varlingam_bootstrap':\n",
    "            adjacency_matrices = run_varlingam_bootstrap(data)\n",
    "            \n",
    "        end_time = time.time()\n",
    "        runtime = round(end_time - start_time, 4)\n",
    "        \n",
    "        if len(adjacency_matrices) > len(ground_truth_matrices):\n",
    "            adjacency_matrices_save = adjacency_matrices[:len(ground_truth_matrices)]\n",
    "        else:\n",
    "            adjacency_matrices_save = adjacency_matrices\n",
    "        plot_heatmap(adjacency_matrices_save, columns, title=f\"Heatmap of Adjacency Matrices from {method}\")\n",
    "        output_file = f'results/real/FinanceCPT/random-rels_20_1{data_type}/adj_matrices_{method}.csv'\n",
    "        save_adjacency_matrices_to_results(adjacency_matrices_save, output_file)\n",
    "        # Evaluate results\n",
    "        evaluation = evaluate_causal_matrices(ground_truth_matrices, adjacency_matrices)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Frobenius': evaluation['fro'],\n",
    "            'SHD': evaluation['shd'],\n",
    "            'F1': evaluation['f1'],\n",
    "            'F1_directed': evaluation['f1_directed'],\n",
    "            'runtime': runtime\n",
    "        })\n",
    "        \n",
    "        # Save results to CSV\n",
    "        df_results = pd.DataFrame(results)\n",
    "        df_results.to_csv(f'results/real/FinanceCPT/random-rels_20_1{data_type}/performance_{method}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = ['A', 'B', 'C', 'D', 'E']\n",
    "data_types = ['E']\n",
    "\n",
    "for data_type in data_types:\n",
    "    print(f\"Running experiments for random-rels_20_1{data_type} data...\")\n",
    "    run_experiment(data_type)\n",
    "\n",
    "print(\"All experiments completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
